{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "net(X)实际上是net.__call__(X)的简写"
      ],
      "metadata": {
        "id": "XzZucDtVUpcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "AzzsNHUhU2VF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#顺序块\n",
        "X = torch.rand(2, 20)\n",
        "class MySequntial(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):  #enumerrate用于同时获取索引和对应的模块\n",
        "            self._modules[str(idx)] = module #将module以有序字典的方式注册到当前模块中\n",
        "    def forward(self, X):\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X\n",
        "net = MySequntial(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISZ86xt1eZV3",
        "outputId": "50542856-236f-4bed-8123-092067890f5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1990,  0.0691,  0.2007, -0.1092, -0.0011, -0.1867,  0.2401, -0.0573,\n",
              "          0.1281, -0.1466],\n",
              "        [-0.1344,  0.0036,  0.1457, -0.0506, -0.0832, -0.0617,  0.2054, -0.0391,\n",
              "          0.1036,  0.0527]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#如何执行自己的数学运算，而不是简单的依赖预定义的神经网络层\n",
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False) #不参与梯度计算，所以将其固定为常量\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "    def forward(self, X):\n",
        "        X = self.linear(X)\n",
        "        #手动操作中间层，加入常量权重\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "        #复用之前的线性层（共享参数）\n",
        "        X = self.linear(X)\n",
        "        #控制流结构，控制X的L1范数的大小\n",
        "        while X.abs().sum() > 1:\n",
        "            X /= 2\n",
        "        return X.sum()\n",
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XngPq6xwXXdO",
        "outputId": "d7ca54b3-ded4-4a1b-fe7c-92b1a3be9dd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0578, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#如何访问参数\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(2, 4)\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, param.shape)\n",
        "for name, param in net[0].named_parameters():\n",
        "    print(name, param.shape)\n",
        "net.state_dict()\n",
        "net.state_dict()['2.bias'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o80EJC-kJdK",
        "outputId": "77fe19c7-326d-48a8-cf05-f9cca8ecefac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([8, 4])\n",
            "0.bias torch.Size([8])\n",
            "2.weight torch.Size([1, 8])\n",
            "2.bias torch.Size([1])\n",
            "weight torch.Size([8, 4])\n",
            "bias torch.Size([8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#参数初始化\n",
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data, net[0].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGOFdPJIjikL",
        "outputId": "f75dbc53-3c6f-4833-95f7-58bdb8be7685"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0084, -0.0050,  0.0035,  0.0119],\n",
              "         [ 0.0010,  0.0081, -0.0020,  0.0146],\n",
              "         [-0.0099,  0.0115,  0.0028, -0.0037],\n",
              "         [ 0.0111,  0.0037,  0.0121,  0.0138],\n",
              "         [-0.0072,  0.0109, -0.0252,  0.0259],\n",
              "         [ 0.0242, -0.0144,  0.0026, -0.0021],\n",
              "         [ 0.0185,  0.0030, -0.0139,  0.0078],\n",
              "         [ 0.0006, -0.0005,  0.0020, -0.0025]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#自定义初始参数分布\n",
        "#对模型中的 nn.Linear 层的 weight 参数用 区间为 [-10, 10] 的均匀分布进行初始化，并且将那些绝对值小于 5 的权重置为 0（实现稀疏性）。\n",
        "def my_init(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    for name, param in m.named_parameters():\n",
        "        print(\"Init\", name, param.shape)\n",
        "        break  # 只打印第一个参数\n",
        "    nn.init.uniform_(m.weight, -10, 10)\n",
        "    m.weight.data *= m.weight.data.abs() >= 5 #abs() 取绝对值后和 5 比较，得到一个布尔Tensor，布尔值在PyTorch中等价于0和1，参与乘法运算\n",
        "net.apply(my_init)\n",
        "net[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKqfMl6vuyV_",
        "outputId": "06a2627b-01b1-4358-a790-0764b3b9c966"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0000,  0.0000,  0.0000, -5.6434],\n",
              "        [ 7.6030,  0.0000,  0.0000, -0.0000],\n",
              "        [-5.9312, -0.0000, -5.0934,  7.8821],\n",
              "        [-0.0000,  0.0000,  0.0000, -6.0444],\n",
              "        [ 0.0000, -8.0181,  5.1119, -0.0000],\n",
              "        [-0.0000, -0.0000,  0.0000,  6.1335],\n",
              "        [ 0.0000,  0.0000,  0.0000,  8.8631],\n",
              "        [ 5.2614, -0.0000, -0.0000, -0.0000]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#加载和保存模型参数\n",
        "class MLP(nn.Module):\n",
        " def __init__(self):\n",
        "  super().__init__()\n",
        "  self.hidden = nn.Linear(20, 256)\n",
        "  self.output = nn.Linear(256, 10)\n",
        " def forward(self, x):\n",
        "  return self.output(F.relu(self.hidden(x)))\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)\n",
        "torch.save(net.state_dict(), 'mlp.params')\n",
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZM3wzvpw4UN",
        "outputId": "21dfd156-2c07-483d-b3c6-65f3f630cd4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA_r2TXvXBCd",
        "outputId": "c69aafdc-50f8-4031-dcac-79f8f2feb28e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 28 16:32:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count() #可用gpu数目"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEx0ri8t4Mr1",
        "outputId": "2bd9e96f-bce0-428f-b10f-cbd91c61f7c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        " \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
        " if torch.cuda.device_count() >= i + 1:\n",
        "  return torch.device(f'cuda:{i}')\n",
        " return torch.device('cpu')\n",
        "def try_all_gpus():\n",
        " \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
        " devices = [torch.device(f'cuda:{i}')\n",
        " for i in range(torch.cuda.device_count())]\n",
        " return devices if devices else [torch.device('cpu')]\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pr3lpTc4jLS",
        "outputId": "6947c73f-6d01-4901-b051-979e262edc45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " device(type='cpu'),\n",
              " [device(type='cuda', index=0)])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3K7a7gR47im"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}